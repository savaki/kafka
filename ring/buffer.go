// Code generated by kafka-protocol-gen. DO NOT EDIT.
//
// Copyright 2019 Matt Ho
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package ring

import (
	"context"
	"sync/atomic"
)

type mutex struct {
	ctx context.Context
	ch  chan struct{}
	set int32
}

func newMutex(ctx context.Context) *mutex {
	return &mutex{
		ctx: ctx,
		ch:  make(chan struct{}),
	}
}

func (m *mutex) Wait() {
	if atomic.CompareAndSwapInt32(&m.set, 0, 1) {
		select {
		case <-m.ctx.Done():
		case m.ch <- struct{}{}:
		}
	}
}

func (m *mutex) Release() {
	if atomic.CompareAndSwapInt32(&m.set, 1, 0) {
		select {
		case <-m.ctx.Done():
		case <-m.ch:
		}
	}
}

// Buffer implements a ring buffer that supports a single reader and
// single writer.
type Buffer struct {
	ctx       context.Context
	cancel    context.CancelFunc
	data      []byte // data provides a temporary internal buffer
	start     int32  // start position of next unread by
	next      int32  // next position to write to
	readLock  *mutex // lockState will either be 0 or 1
	writeLock *mutex // lockState will either be 0 or 1
	size      int32  // size of internal buffer
}

// NewRingBuffer returns a new ringBuffer suitable for a single reader and a single writer
func New(size int) *Buffer {
	ctx, cancel := context.WithCancel(context.Background())
	return &Buffer{
		ctx:       ctx,
		cancel:    cancel,
		data:      make([]byte, size),
		readLock:  newMutex(ctx),
		writeLock: newMutex(ctx),
		size:      int32(size),
	}
}

func (r *Buffer) Close() error {
	r.cancel()
	return nil
}

// WriteN writes the first n bytes from data to the buffer.  If buffer is full, WriteN
// blocks until ReadN clears space
func (r *Buffer) WriteN(data []byte, n int) {
	var (
		pos   = atomic.LoadInt32(&r.next)  // position next byte should be written
		start = atomic.LoadInt32(&r.start) // start of data
		wrote int                          // bytes written since last lock
	)

	for i := 0; i < n; i++ {
		r.data[pos] = data[i]
		pos = incr(pos, r.size)

		// whenever pos catches up to the starting position, wait for
		// additional bytes to be written before continuing
		if next := incr(pos, r.size); next == start {
			atomic.StoreInt32(&r.next, pos)

			// important to store pos prior to reading from lockMux
			r.readLock.Release()
			wrote = i

			start = atomic.LoadInt32(&r.start)
			if next := incr(pos, r.size); next == start {
				r.writeLock.Wait()
			}
		}
	}

	atomic.StoreInt32(&r.next, pos)

	// if at least one byte has been written since the last time r.lock
	// was cleared, check to see if it needs to be cleared again
	if n > wrote+1 {
		r.readLock.Release()
	}
}

// ReadN reads n bytes in the byte array provided.  If insufficient bytes
// are available, blocks until WriteN refills the buffer.
func (r *Buffer) ReadN(data []byte, n int) {
	var (
		pos  = atomic.LoadInt32(&r.start)
		next = atomic.LoadInt32(&r.next)
		read = 0
	)

	for i := 0; i < n; i++ {
		if pos == next {
			atomic.StoreInt32(&r.start, pos)
			if read > 0 {
				r.writeLock.Release()
			}

			next = atomic.LoadInt32(&r.next)
			if pos == next {
				r.readLock.Wait()
			}
		}

		data[i] = r.data[pos]
		pos = incr(pos, r.size)
		read++
	}

	atomic.StoreInt32(&r.start, pos)
	if read > 0 {
		r.writeLock.Release()
	}
}

func incr(pos, size int32) int32 {
	pos++
	if pos == size {
		return 0
	}
	return pos
}
